{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as httpr\n",
    "from pprint import pprint\n",
    "\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# @NOTE: Replace the path with your actual path to the chromedriver\n",
    "#executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA's Mars InSight Flexes Its Arm\n",
      "Now unstowed, the spacecraft's robotic arm will point a camera located on its elbow and take images of the surroundings.\n"
     ]
    }
   ],
   "source": [
    "#for the sake of performance and my own learning I will be using the Request library for retrieving the HTML since it will not need to laod images.\n",
    "\n",
    "#retrieve nasa news items\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "url = \"https://mars.nasa.gov/news/\"\n",
    "browser.visit(url)\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "article_title = soup.find(\"div\", class_=\"content_title\").get_text()\n",
    "article_body = soup.find(\"div\", class_=\"article_teaser_body\").get_text()\n",
    "print(article_title)\n",
    "print(article_body)\n",
    "\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA14934_hires.jpg\n"
     ]
    }
   ],
   "source": [
    "#retrieve latest nasa mars image url\n",
    "base_url = \"https://www.jpl.nasa.gov\"\n",
    "url = base_url + \"/spaceimages/?search=&category=Mars\"\n",
    "http_result = httpr.get(url)\n",
    "\n",
    "soup = BeautifulSoup(http_result.content, \"html.parser\")\n",
    "\n",
    "image_page_url = soup.find(\"a\", class_=\"button fancybox\")['data-link']\n",
    "new_url = base_url + image_page_url\n",
    "\n",
    "http_result = httpr.get(new_url)\n",
    "soup = BeautifulSoup(http_result.content, \"html.parser\")\n",
    "\n",
    "full_img_page_url = base_url + soup.find(\"img\", class_=\"main_image\")['src']\n",
    "print(full_img_page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done! That 30 minutes of EDL dust settling was very effective. Shame #InSight can’t act as a supercharger for @marsrovers Oppy, she sure could use a boost right now.https://twitter.com/NASAInSight/status/1068661716756516864 …\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get the latest tweet from the Mars Weather account\n",
    "url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "http_result = httpr.get(url)\n",
    "quoted_tweet_optional = \"\"\n",
    "\n",
    "soup = BeautifulSoup(http_result.content, \"html.parser\")\n",
    "\n",
    "tweet_text = soup.find(\"p\", class_=\"tweet-text\").get_text()\n",
    "if soup.find(\"p\", class_=\"QuoteTweet-text\") != None:\n",
    "    quoted_tweet_optional = soup.find(\"p\", class_=\"QuoteTweet-text\").get_text()\n",
    "print(tweet_text)\n",
    "print(quoted_tweet_optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<table border=\"1\" class=\"dataframe table-striped\">\\n'\n",
      " '  <thead>\\n'\n",
      " '    <tr style=\"text-align: right;\">\\n'\n",
      " '      <th></th>\\n'\n",
      " '      <th>Feature</th>\\n'\n",
      " '      <th>Value</th>\\n'\n",
      " '    </tr>\\n'\n",
      " '  </thead>\\n'\n",
      " '  <tbody>\\n'\n",
      " '    <tr>\\n'\n",
      " '      <th>0</th>\\n'\n",
      " '      <td>Equatorial Diameter:</td>\\n'\n",
      " '      <td>6,792 km</td>\\n'\n",
      " '    </tr>\\n'\n",
      " '    <tr>\\n'\n",
      " '      <th>1</th>\\n'\n",
      " '      <td>Polar Diameter:</td>\\n'\n",
      " '      <td>6,752 km</td>\\n'\n",
      " '    </tr>\\n'\n",
      " '    <tr>\\n'\n",
      " '      <th>2</th>\\n'\n",
      " '      <td>Mass:</td>\\n'\n",
      " '      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n'\n",
      " '    </tr>\\n'\n",
      " '    <tr>\\n'\n",
      " '      <th>3</th>\\n'\n",
      " '      <td>Moons:</td>\\n'\n",
      " '      <td>2 (Phobos &amp; Deimos)</td>\\n'\n",
      " '    </tr>\\n'\n",
      " '    <tr>\\n'\n",
      " '      <th>4</th>\\n'\n",
      " '      <td>Orbit Distance:</td>\\n'\n",
      " '      <td>227,943,824 km (1.52 AU)</td>\\n'\n",
      " '    </tr>\\n'\n",
      " '    <tr>\\n'\n",
      " '      <th>5</th>\\n'\n",
      " '      <td>Orbit Period:</td>\\n'\n",
      " '      <td>687 days (1.9 years)</td>\\n'\n",
      " '    </tr>\\n'\n",
      " '    <tr>\\n'\n",
      " '      <th>6</th>\\n'\n",
      " '      <td>Surface Temperature:</td>\\n'\n",
      " '      <td>-153 to 20 °C</td>\\n'\n",
      " '    </tr>\\n'\n",
      " '    <tr>\\n'\n",
      " '      <th>7</th>\\n'\n",
      " '      <td>First Record:</td>\\n'\n",
      " '      <td>2nd millennium BC</td>\\n'\n",
      " '    </tr>\\n'\n",
      " '    <tr>\\n'\n",
      " '      <th>8</th>\\n'\n",
      " '      <td>Recorded By:</td>\\n'\n",
      " '      <td>Egyptian astronomers</td>\\n'\n",
      " '    </tr>\\n'\n",
      " '  </tbody>\\n'\n",
      " '</table>')\n"
     ]
    }
   ],
   "source": [
    "#retrieve the facts table and load to a dataframe\n",
    "url = \"http://space-facts.com/mars/\"\n",
    "\n",
    "mars_facts_df = pd.DataFrame(pd.read_html(url)[0])\n",
    "mars_facts_df.columns = [\"Feature\", \"Value\"]\n",
    "html_table = mars_facts_df.to_html(classes='table-striped')\n",
    "pprint(html_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'original_image_url': 'https://astrogeology.usgs.govhttp://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif',\n",
      "  'title': 'Cerberus Hemisphere Enhanced',\n",
      "  'url_jpg': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg'},\n",
      " {'original_image_url': 'https://astrogeology.usgs.govhttp://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif',\n",
      "  'title': 'Schiaparelli Hemisphere Enhanced',\n",
      "  'url_jpg': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg'},\n",
      " {'original_image_url': 'https://astrogeology.usgs.govhttp://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif',\n",
      "  'title': 'Syrtis Major Hemisphere Enhanced',\n",
      "  'url_jpg': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg'},\n",
      " {'original_image_url': 'https://astrogeology.usgs.govhttp://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif',\n",
      "  'title': 'Valles Marineris Hemisphere Enhanced',\n",
      "  'url_jpg': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://astrogeology.usgs.gov\"\n",
    "url = base_url + \"/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "http_result = httpr.get(url)\n",
    "\n",
    "soup = BeautifulSoup(http_result.content, \"html.parser\")\n",
    "hemisphere_img_info = []\n",
    "original_img_url = ''\n",
    "\n",
    "for link in soup.find_all(\"a\", class_=\"product-item\"):\n",
    "    image_text = link.get_text()\n",
    "    \n",
    "    url = base_url + link[\"href\"]\n",
    "    http_result = httpr.get(url)\n",
    "    image_soup = BeautifulSoup(http_result.content, \"html.parser\")\n",
    "    image_url = base_url + image_soup.find(\"img\", class_=\"wide-image\")[\"src\"]\n",
    "    \n",
    "    for img_link in image_soup.find_all(\"a\"):\n",
    "        if (img_link.get_text() == 'Original'):\n",
    "            original_img_url = base_url + img_link['href']\n",
    "            \n",
    "    img_info = {\"title\": image_text,\n",
    "               \"url_jpg\": image_url,\n",
    "               \"original_image_url\": original_img_url}\n",
    "    \n",
    "    hemisphere_img_info.append(img_info)\n",
    "    \n",
    "pprint(hemisphere_img_info)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
